{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hatsuhinode/ML-Algorithm/blob/main/Linear_Regression_Gradient_Descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression using gradient descent"
      ],
      "metadata": {
        "id": "KSIgnTKrnf__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Gradient Descent* is an optimization algorithm for finding optimal solutions to wide range of problems. The idea of Gradient Descent is to tweak parameters iteratively in order to minimize a cost function."
      ],
      "metadata": {
        "id": "QLgKggGvnzAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It measures the local gradient of the error function with regard to the parameter vector **θ** and it goes in the direction of descending gradient."
      ],
      "metadata": {
        "id": "jQCDAeFlolxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient** means an increase or decrease in the magnitude of a property. It simply means *slope*."
      ],
      "metadata": {
        "id": "QHHfeDzKo8uA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Gradient Descent* measures the local gradient of the error function with regard to the parameter vector θ, and it goes in the direction of descending gradient. Once the gradient is zero, you have reached a minimum"
      ],
      "metadata": {
        "id": "2sXKpOo38ii7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You start by filling **θ** with random values (this is called random initialization). Then you improve it gradually, taking one baby step at a time, each step attempting to decrease the cost function (e.g., the MSE), until the algorithm converges to a minimum"
      ],
      "metadata": {
        "id": "VG4Orv3s83Km"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An important parameter in Gradient Descent is the **size of the steps**, determined by the **learning rate** hyperparameter."
      ],
      "metadata": {
        "id": "kaNNidYY9fwH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning rate\n",
        "* If learning rate is too high might make the algorithm diverge, with larger and larger values, failing to find a good solution.\n",
        "\n",
        "* If the learning rate is too small, then the algorithm will have to go through many iterations to converge, which will take a long time."
      ],
      "metadata": {
        "id": "XR2lXG2l99lz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Point to consider\n",
        "\n",
        "When using Gradient Descent, you should ensure that all features have a similar scale\n",
        "(e.g., using Scikit-Learn’s *StandardScaler class)*, or else it will take much longer to converge."
      ],
      "metadata": {
        "id": "sSYe3DR__7I-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Gradient Descent* is a search in the model’s *parameter space*: the more parameters a model has, the more dimensions this space has, and the harder the search is."
      ],
      "metadata": {
        "id": "MmeVImVNAY3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Gradient Descent"
      ],
      "metadata": {
        "id": "OTc5vLE7Ao-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "8_6VQC5-NC9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=2 * np.random.rand(100,1)\n",
        "y=4 + 3 * X + np.random.randn(100,1)"
      ],
      "metadata": {
        "id": "QDvLBHlnNCFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding x0=1 to each instance.\n",
        "X_b=np.c_[np.ones((100,1)),X]"
      ],
      "metadata": {
        "id": "465BmpxJNI5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing learing rate.\n",
        "eta=0.1\n",
        "n_iterations=1000\n",
        "m=100\n",
        "\n",
        "# Random initialization of parameter.\n",
        "theta=np.random.randn(2,1)\n",
        "\n",
        "for iterations in range(n_iterations):\n",
        "  gradients=2/m*X_b.T.dot(X_b.dot(theta)-y)\n",
        "  theta=theta-eta*gradients"
      ],
      "metadata": {
        "id": "Qlbgwv2t8zBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_jCqYLNNZdF",
        "outputId": "e9a45213-c77a-4a9f-eaa9-2f14fe29241c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.90690054],\n",
              "       [3.03066399]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "m is the number of training instances and n is the number of features"
      ],
      "metadata": {
        "id": "BrrO-1xlZ6oP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "u4TMh1n2Q9ct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stochastic Gradient Descent picks a random instance in the training set at every step and computes the gradients based only on that single instance."
      ],
      "metadata": {
        "id": "vFQWSRSqR3c0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the other hand, due to its stochastic (i.e., random) nature, this algorithm is much less regular than Batch Gradient Descent: instead of gently decreasing until it reaches the minimum, the cost function will bounce up and down, decreasing only on average. Over time it will end up very close to the minimum, but once it gets there it will continue to bounce around, never settling down. So once the algorithm stops, the final parameter values are good, but not optimal."
      ],
      "metadata": {
        "id": "58-1gwl2S74j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "When the cost function is very irregular,this can actually help the algorithm jump out of local minima, so Stochastic Gradient Descent has a better chance of finding the global minimum than Batch Gradient Descent does."
      ],
      "metadata": {
        "id": "6fpWQIRBTRYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, randomness is good to escape from local optima, but bad because it means that the algorithm can never settle at the minimum"
      ],
      "metadata": {
        "id": "hjC_G5hXThX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One solution to this dilemma is to gradually reduce the learning rate. The steps start out large (which helps make quick progress and escape local minima), then get smaller and smaller, allowing the algorithm to settle at the global minimum."
      ],
      "metadata": {
        "id": "D67sNkuqTxRl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function that determines the learning rate at each iteration is called the *learning schedule*."
      ],
      "metadata": {
        "id": "OW7UaNguT1ii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the learning rate is reduced too quickly, you may get stuck in a local minimum, or even end up frozen halfway to the minimum. If the learning rate is reduced too slowly, you may jump around the minimum for a long time and end up with a suboptimal solution if you halt training too early."
      ],
      "metadata": {
        "id": "ckVKwSd_UbiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs=50\n",
        "t0,t1=5,50 # Learning schedule hyperparameters."
      ],
      "metadata": {
        "id": "WuDX2VRgNpQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def learning_schedule(t):\n",
        "  return t0/(t+t1)"
      ],
      "metadata": {
        "id": "WGoQ8rRMU7gY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta=np.random.randn(2,1) # Random initialization."
      ],
      "metadata": {
        "id": "b-NAjyVeVPmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epochs in range(n_epochs):\n",
        "  for i in range(m):\n",
        "    random_index=np.random.randint(m)\n",
        "    xi=X_b[random_index:random_index+1]\n",
        "    yi=y[random_index:random_index+1]\n",
        "    gradients=2 * xi.T.dot(xi.dot(theta)-yi)\n",
        "    eta=learning_schedule(epochs * m +i)\n",
        "    theta=theta- eta * gradients"
      ],
      "metadata": {
        "id": "orOX_cEwVVxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_ZJwza5VgpH",
        "outputId": "41b0e2e4-fddf-43c8-e469-bf865c01e5f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.95394165],\n",
              "       [2.96829998]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When using Stochastic Gradient Descent, the training instances must be independent and identically distributed (IID) to ensure that the parameters get pulled toward the global optimum, on average. A simple way to ensure this is to shuffle the instances during training (e.g., pick each instance randomly, or shuffle the training set at the beginning of each epoch). If you do not shuffle the instances—for example, if the instances are sorted by label—then SGD will start by optimizing for one label, then the next, and so on, and it will not settle close to the global minimum."
      ],
      "metadata": {
        "id": "oqzHdKN2YHM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor"
      ],
      "metadata": {
        "id": "4bairJ2dXcQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_reg=SGDRegressor(max_iter=1000,tol=1e-3,penalty=None,eta0=0.1)\n",
        "sgd_reg.fit(X,y.ravel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W4w6yUxYppx",
        "outputId": "f1707494-7854-49d5-aa60-305044803fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDRegressor(eta0=0.1, penalty=None)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *numpy.ravel()* functions returns contiguous flattened array(1D array with all the input-array elements and with the same type as it)"
      ],
      "metadata": {
        "id": "ujgKUbgOacKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code doesnot use any regularization(penalty=None)"
      ],
      "metadata": {
        "id": "5BIZvPp6YzcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_reg.intercept_,sgd_reg.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIRPng9nY_Ju",
        "outputId": "11196fcf-e2f2-46aa-a0bf-4b1d92928b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([3.82099108]), array([2.95560505]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mini-batch Gradient Descent"
      ],
      "metadata": {
        "id": "7dMwicGfZLm9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At each step, instead of computing the gradients based on the full training set (as in Batch GD) or based on just one instance (as in Stochastic GD), Mini-batch GD computes the gradients on small random sets of instances called mini-batches."
      ],
      "metadata": {
        "id": "YPLNQAwnZPIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main advantage of Mini- batch GD over Stochastic GD is that you can get a performance boost from hardware optimization of matrix operations, especially when using GPUs."
      ],
      "metadata": {
        "id": "LY57ErPXZZoc"
      }
    }
  ]
}